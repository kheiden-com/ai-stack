# Local AI Stack

This includes:
- Inference runtime (ollama)
- Vector Database (qdrant)
- Application Frontend (OpenWebUi)
- Workflow Automation (n8n)
- Multimedia Management (photoprism)


## Getting Started
```
git clone ...
docker-compose up -d
```

Requires availability of the following ports:
```
3000
```



## Future Updates

TODO: Acquire X free ports on host machine, create port variables for each, configure each container with environment variables which reference these available ports.

